{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74143c50-c2a8-41c4-9b23-28692e8efb58",
   "metadata": {},
   "source": [
    "# Bidirectional LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38790fb-d416-4f60-ad9d-4edf988c8b2f",
   "metadata": {},
   "source": [
    "Bidirectional LSTM to capture both forward and backward dependencies in the time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ba92eb-9db2-47d6-ab96-2368defacfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"../data/clean_FeatEng.csv\" #\"../data/ml-engineer-dataset-clean.csv\"\n",
    "df_cleaned = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd222f8-ecba-4ace-97b6-1019c8a00574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 22:31:12.921198: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (31817, 24, 5), Test shape: (7955, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Select relevant features\n",
    "features = [\"demand-forecast\", \"wind-forecast\", \"solar-forecast\", \"temperature-forecast\", \"day-ahead-auction-price\"]\n",
    "target = \"day-ahead-auction-price\"\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_cleaned[features])\n",
    "\n",
    "# Convert data into sequences\n",
    "def create_sequences(data, seq_length=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length, -1])  # Predict price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LENGTH = 24  # Use past 24 hours to predict next price\n",
    "X, y = create_sequences(df_scaled, SEQ_LENGTH)\n",
    "\n",
    "# Train-test split\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac90202-7fee-43ea-9b52-f9bf10fc8114",
   "metadata": {},
   "source": [
    "# Define the BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5fffb2a-f7a4-4884-98eb-f3939f12a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "\n",
    "def build_bilstm():\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(64, return_sequences=True), input_shape=(SEQ_LENGTH, X_train.shape[2])),\n",
    "        Dropout(0.3),\n",
    "        Bidirectional(LSTM(32, return_sequences=False)),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d94e674-4587-4869-bc7a-64a157143f15",
   "metadata": {},
   "source": [
    "# Train the BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9309a9e-0c1b-45cb-b7d3-b309382449cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alfonzo/Library/Application Support/pipx/venvs/jupyterlab/lib/python3.12/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - loss: 0.0831 - val_loss: 0.0342\n",
      "Epoch 2/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0365 - val_loss: 0.0318\n",
      "Epoch 3/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0301 - val_loss: 0.0270\n",
      "Epoch 4/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0274 - val_loss: 0.0235\n",
      "Epoch 5/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 0.0263 - val_loss: 0.0235\n",
      "Epoch 6/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0250 - val_loss: 0.0228\n",
      "Epoch 7/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0248 - val_loss: 0.0240\n",
      "Epoch 8/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0244 - val_loss: 0.0228\n",
      "Epoch 9/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0243 - val_loss: 0.0218\n",
      "Epoch 10/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0246 - val_loss: 0.0223\n",
      "Epoch 11/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0240 - val_loss: 0.0219\n",
      "Epoch 12/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0239 - val_loss: 0.0225\n",
      "Epoch 13/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0234 - val_loss: 0.0256\n",
      "Epoch 14/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0232 - val_loss: 0.0213\n",
      "Epoch 15/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0228 - val_loss: 0.0218\n",
      "Epoch 16/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0229 - val_loss: 0.0220\n",
      "Epoch 17/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0228 - val_loss: 0.0225\n",
      "Epoch 18/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0221 - val_loss: 0.0225\n",
      "Epoch 19/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 20/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0218 - val_loss: 0.0264\n",
      "Epoch 21/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0217 - val_loss: 0.0227\n",
      "Epoch 22/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0216 - val_loss: 0.0230\n",
      "Epoch 23/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0212 - val_loss: 0.0267\n",
      "Epoch 24/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0209 - val_loss: 0.0317\n",
      "Epoch 25/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0206 - val_loss: 0.0284\n",
      "Epoch 26/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0205 - val_loss: 0.0262\n",
      "Epoch 27/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0204 - val_loss: 0.0289\n",
      "Epoch 28/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0201 - val_loss: 0.0295\n",
      "Epoch 29/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0201 - val_loss: 0.0280\n",
      "Epoch 30/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0203 - val_loss: 0.0290\n",
      "Epoch 31/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 0.0200 - val_loss: 0.0273\n",
      "Epoch 32/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0196 - val_loss: 0.0250\n",
      "Epoch 33/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0200 - val_loss: 0.0280\n",
      "Epoch 34/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - loss: 0.0195 - val_loss: 0.0310\n",
      "Epoch 35/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0191 - val_loss: 0.0285\n",
      "Epoch 36/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0191 - val_loss: 0.0249\n",
      "Epoch 37/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0191 - val_loss: 0.0268\n",
      "Epoch 38/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0190 - val_loss: 0.0281\n",
      "Epoch 39/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0190 - val_loss: 0.0276\n",
      "Epoch 40/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0190 - val_loss: 0.0268\n",
      "Epoch 41/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0188 - val_loss: 0.0288\n",
      "Epoch 42/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0189 - val_loss: 0.0273\n",
      "Epoch 43/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0185 - val_loss: 0.0285\n",
      "Epoch 44/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0187 - val_loss: 0.0257\n",
      "Epoch 45/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0190 - val_loss: 0.0286\n",
      "Epoch 46/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0186 - val_loss: 0.0275\n",
      "Epoch 47/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0186 - val_loss: 0.0283\n",
      "Epoch 48/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0186 - val_loss: 0.0276\n",
      "Epoch 49/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0186 - val_loss: 0.0304\n",
      "Epoch 50/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0183 - val_loss: 0.0283\n",
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_absolute_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m y_test_rescaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(np\u001b[38;5;241m.\u001b[39mhstack((X_test[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y_test\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))))[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m(y_test_rescaled, y_pred_rescaled)\n\u001b[1;32m     16\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBiLSTM Model - MAE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_absolute_error' is not defined"
     ]
    }
   ],
   "source": [
    "bilstm_model = build_bilstm()\n",
    "\n",
    "history = bilstm_model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test),\n",
    "    epochs=50, batch_size=32, verbose=1\n",
    ")\n",
    "\n",
    "y_pred = bilstm_model.predict(X_test)\n",
    "\n",
    "# Reverse scaling\n",
    "y_pred_rescaled = scaler.inverse_transform(np.hstack((X_test[:, -1, :-1], y_pred.reshape(-1, 1))))[:, -1]\n",
    "y_test_rescaled = scaler.inverse_transform(np.hstack((X_test[:, -1, :-1], y_test.reshape(-1, 1))))[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43eeeb1a-43c8-4ae2-b996-8118e3a92f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM Model - MAE: 9.82, RMSE: 14.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
    "\n",
    "print(f\"BiLSTM Model - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883c867-81f3-46ad-9b30-005ba6e22716",
   "metadata": {},
   "source": [
    "| Model                                            | Mae lower is better | Rmse lower is better |\n",
    "| :----------------------------------------------- | :------------------ | :------------------- |\n",
    "| Historical Average                               | 30.37               | 40.85                |\n",
    "| Initial Linear Regression                        | 17.7                | 23.81                |\n",
    "| Improved Linear Regression (Feature Engineering) | 16.24               | 21.42                |\n",
    "| XGBoost (Default Settings)                       | 15.12               | 20.06                |\n",
    "| Tuned XGBoost (Hyperparameter Search)            | 14.86               | 19.73                |\n",
    "| Stacked Model (XGBoost + LightGBM + Ridge)       | 15.33               | 20.39                |\n",
    "| lightGBM (tuned)                                 | 15.93               | 20.81                |\n",
    "| Stacked Model with tuned LGBM                    | 15.47               | 20.41                |\n",
    "| LSTMs                                            | 11.74               | 15.19                |\n",
    "| CNN-LSTM                                         | 12.27               | 17.58                |\n",
    "| **BiLSTM**                                       | **9.82**            | **14.61**            |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fff071-d565-44b5-9807-6f4e35579d7c",
   "metadata": {},
   "source": [
    "## Generate Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa86340-e44f-414a-ad1b-ed3570bd4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13158ba8-ba41-4a3b-bbe9-7c2d6003560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for day-ahead price, demand, wind, and solar forecasts\n",
    "lag_features = ['day-ahead-auction-price', 'demand-forecast', 'wind-forecast', 'solar-forecast']\n",
    "\n",
    "for feature in lag_features:\n",
    "    for lag in [1, 2, 3, 7]:  # 1-hour, 2-hour, 3-hour, 1-day lags\n",
    "        df[f'{feature}_lag{lag}'] = df[feature].shift(lag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bc358-9594-467b-8327-16771a536990",
   "metadata": {},
   "source": [
    "## Add Rolling Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239d9387-0ed9-42fe-8a95-9553704f352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rolling mean & std for the last 3, 6, and 12 hours\n",
    "for feature in lag_features:\n",
    "    for window in [3, 6, 12]:\n",
    "        df[f'{feature}_roll_mean{window}'] = df[feature].rolling(window=window).mean()\n",
    "        df[f'{feature}_roll_std{window}'] = df[feature].rolling(window=window).std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43389cf3-9ec4-4c8c-9536-1f01a3460edd",
   "metadata": {},
   "source": [
    "## Fourier Features for Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87119189-fd9e-4b56-a531-6eb8280cc51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_fourier_terms(df, period, K):\n",
    "    \"\"\"Add Fourier terms to capture periodic patterns.\"\"\"\n",
    "    time = np.arange(len(df))\n",
    "    for k in range(1, K+1):\n",
    "        df[f'sin_{k}_period{period}'] = np.sin(2 * np.pi * k * time / period)\n",
    "        df[f'cos_{k}_period{period}'] = np.cos(2 * np.pi * k * time / period)\n",
    "    return df\n",
    "\n",
    "# Add weekly and daily seasonalities\n",
    "df = add_fourier_terms(df, period=24, K=3)  # Daily\n",
    "df = add_fourier_terms(df, period=24*7, K=3)  # Weekly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba8327-6d2e-4aac-b365-b42d44d741dc",
   "metadata": {},
   "source": [
    "## Preprocess Data with New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3295f8-b190-48cf-9964-42e731cd1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "\n",
    "# Define features and target\n",
    "target = 'day-ahead-auction-price'\n",
    "features = df.columns.difference(['contract-delivery', target])  # Exclude non-numeric\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df[features])\n",
    "\n",
    "# Convert to sequences for LSTM\n",
    "SEQ_LENGTH = 24  # Use past 24 hours for prediction\n",
    "\n",
    "def create_sequences(data, target, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(target[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(df_scaled, df[target].values, SEQ_LENGTH)\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ee699d-c093-48dc-856e-865b42194bb1",
   "metadata": {},
   "source": [
    "## Define & Train BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5aac8fdc-5e0f-48ed-aa41-ad134ec38d49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alfonzo/Library/Application Support/pipx/venvs/jupyterlab/lib/python3.12/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - loss: 0.0810 - val_loss: 0.0364\n",
      "Epoch 2/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0363 - val_loss: 0.0300\n",
      "Epoch 3/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 0.0310 - val_loss: 0.0292\n",
      "Epoch 4/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 0.0291 - val_loss: 0.0246\n",
      "Epoch 5/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 0.0269 - val_loss: 0.0274\n",
      "Epoch 6/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0258 - val_loss: 0.0244\n",
      "Epoch 7/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0247 - val_loss: 0.0224\n",
      "Epoch 8/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0243 - val_loss: 0.0232\n",
      "Epoch 9/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0246 - val_loss: 0.0292\n",
      "Epoch 10/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0243 - val_loss: 0.0231\n",
      "Epoch 11/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0237 - val_loss: 0.0244\n",
      "Epoch 12/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0233 - val_loss: 0.0220\n",
      "Epoch 13/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0230 - val_loss: 0.0222\n",
      "Epoch 14/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0228 - val_loss: 0.0245\n",
      "Epoch 15/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0228 - val_loss: 0.0217\n",
      "Epoch 16/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0218 - val_loss: 0.0228\n",
      "Epoch 17/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0218 - val_loss: 0.0230\n",
      "Epoch 18/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0216 - val_loss: 0.0269\n",
      "Epoch 19/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0214 - val_loss: 0.0242\n",
      "Epoch 20/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0215 - val_loss: 0.0284\n",
      "Epoch 21/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0207 - val_loss: 0.0271\n",
      "Epoch 22/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0208 - val_loss: 0.0290\n",
      "Epoch 23/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0210 - val_loss: 0.0292\n",
      "Epoch 24/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0201 - val_loss: 0.0301\n",
      "Epoch 25/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0205 - val_loss: 0.0374\n",
      "Epoch 26/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0201 - val_loss: 0.0344\n",
      "Epoch 27/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0199 - val_loss: 0.0365\n",
      "Epoch 28/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0199 - val_loss: 0.0332\n",
      "Epoch 29/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0198 - val_loss: 0.0403\n",
      "Epoch 30/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0197 - val_loss: 0.0368\n",
      "Epoch 31/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0195 - val_loss: 0.0385\n",
      "Epoch 32/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0200 - val_loss: 0.0443\n",
      "Epoch 33/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0195 - val_loss: 0.0474\n",
      "Epoch 34/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 0.0197 - val_loss: 0.0402\n",
      "Epoch 35/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0195 - val_loss: 0.0423\n",
      "Epoch 36/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0190 - val_loss: 0.0415\n",
      "Epoch 37/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0194 - val_loss: 0.0382\n",
      "Epoch 38/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0195 - val_loss: 0.0382\n",
      "Epoch 39/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0193 - val_loss: 0.0455\n",
      "Epoch 40/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0194 - val_loss: 0.0395\n",
      "Epoch 41/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0191 - val_loss: 0.0384\n",
      "Epoch 42/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - loss: 0.0189 - val_loss: 0.0410\n",
      "Epoch 43/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0189 - val_loss: 0.0421\n",
      "Epoch 44/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0186 - val_loss: 0.0446\n",
      "Epoch 45/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0189 - val_loss: 0.0418\n",
      "Epoch 46/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 0.0188 - val_loss: 0.0416\n",
      "Epoch 47/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0186 - val_loss: 0.0413\n",
      "Epoch 48/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m958s\u001b[0m 964ms/step - loss: 0.0185 - val_loss: 0.0456\n",
      "Epoch 49/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - loss: 0.0185 - val_loss: 0.0361\n",
      "Epoch 50/50\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step - loss: 0.0185 - val_loss: 0.0407\n"
     ]
    }
   ],
   "source": [
    "# Define BiLSTM model\n",
    "def build_bilstm():\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(64, return_sequences=True), input_shape=(SEQ_LENGTH, X_train.shape[2])),\n",
    "        Dropout(0.3),\n",
    "        Bidirectional(LSTM(32, return_sequences=False)),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "bilstm_model = build_bilstm()\n",
    "\n",
    "# Train model\n",
    "history = bilstm_model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test),\n",
    "    epochs=50, batch_size=32, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976f7a8-4b0b-4016-b2ae-de221be17be5",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44d16122-0028-42cc-b4ae-3d6f4a41ae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n",
      "BiLSTM with Feature Engineering - MAE: 14.13, RMSE: 18.67\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = bilstm_model.predict(X_test)\n",
    "\n",
    "# Reverse scaling\n",
    "y_pred_rescaled = scaler.inverse_transform(np.hstack((X_test[:, -1, :-1], y_pred.reshape(-1, 1))))[:, -1]\n",
    "y_test_rescaled = scaler.inverse_transform(np.hstack((X_test[:, -1, :-1], y_test.reshape(-1, 1))))[:, -1]\n",
    "\n",
    "# Compute error metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
    "\n",
    "print(f\"BiLSTM with Feature Engineering - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13c726-468a-43e4-b29b-91e39bed1b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
